# Basic Data Manipulation

## Intended Learning Outcomes {-}

Be able to use the following dplyr one-table verbs:

* select()
* arrange()
* filter()
* mutate()
* group_by()
* summarise()


## Data Wrangling

It is estimated that data scientists spend between 50-80% of their time cleaning and preparing data. This so-called **data wrangling** is a crucial first step in organising data for subsequent analysis (NYTimes., 2014). The goal is generally to get the data into a "tidy" format whereby each variable is a column, each observation is a row and each value is a cell. The `tidyverse` package, developed by Hadley Wickham, is a collection of R packages built around this basic concept and intended to make data science fast, easy and fun. It contains six core packages: dplyr, tidyr, readr, purrr, ggplot2, and tibble. 

`dplyr` provides a useful selection of functions - each corresponding to a basic verb: 


| dplyr function | description  |
|:----------|:---------------------------|
| select() | Include or exclude certain variables (columns)  |
| arrange() | Reorder observations (rows) |
| filter() | Include or exclude certain observations (rows) |
|	mutate() | Create new variables (columns) and preserve existing ones |
|	group_by() | Organise observations (rows) by variables (columns) |
|	summarise() | Compute summary statistics for selected variables (columns) |

These are termed **one table verbs** as they only operate on one table at a time. Today we will examine the Wickham Six; select(), arrange(), filter(), mutate(), group_by(), and summarise().


## Pre-Steps

Before we can talk about today's data, let's do some house-keeping first.

### Downloading materials

Download the materials we will be working with today from moodle. The zip folder that contains an Rmd file called `L3_stub`, and a data file called `CareerStats.csv`. Similar to last week, `L3_stub` contains all code chunks for today's lesson, and is intended for you to add notes and comments.


### Unzipping the zip folder

Make sure you **unzip the folder** and check it contains the `L3_stub.Rmd` and `CareerStats.csv`. 


### Setting the working directory

Set that folder as your working directory for today. The files in the folders should now be visible in the `Files pane`.


### Loading in the required packages into the library

As we will be using functions that are part of `tidyverse`, we need to load it into the library. You will also need to load in the new package `babynames`. You will need to have this package installed first before you can load it into the library, if you haven't done that yet use the `install.packages()` function down in your console first.

```{r L3, message=FALSE}
library(tidyverse)
library(babynames)
```


### Read in the data

Now, today we will work with two different datasets, one fairly simple dataset, and another more messy complex dataset later one.

The first is a large dataset about babynames (big surprise!). The package you installed and loaded into the library is infact a readymade dataset, that can be read straight into the `Global Environment`. We will deal with the second dataset later.



```{r}
Name_Data <- babynames
```


### View the data

Click on `Name_Data` in your `Global Environment` to open your data in a new tab on the `Source` pane or call the object in your `Console` (by typing the name of the object `Name_Data`) to check that the data was correctly imported into R.

```{r}
Name_Data
```


```{block, type="funfact"}
You could also view the data by using the function `View()`. If you are more of a typer than a mouse-user you can type `View(Name_Data)` into your `Console`. This will open the data in a read-only, spreadsheet-like format in a new tab on the `Source` pane.
```


Remember from last week, we can also use `glimpse()` to view the columns and their datatypes.

```{r}
glimpse(Name_Data)
```

`head()` would be helpful in displaying only the first 6 rows of the dataset, but remember not to get "tricked" by the number of observations shown in the output.

```{r}
head(Name_Data)
```


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

How many rows (or observations) does `Name_Data` have? `r fitb("1924665")` <br>
How many columns (or variables) does `Name_Data` have? `r fitb("5")` <br>


```{block, type="task"}
Take some time to familiarise yourself with the variables in your dataframe. 
```


## select()

You may not want to include every single variable in your analysis. In order to include or exclude certain variables (columns), use the `select()` function. The first argument to this function is the object you want to select variables from (i.e. our tibble called `Name_Data`), and the subsequent arguments are the variables to keep.


For example, if you wanted to keep all variables except from `prop`, you could type:

```{r}
select(Name_Data, year, sex, name, n)
```

That works fine when you have realtively few variables like this dataset, however this menthod can become very time consuming if you have a lot of varibales in  your dataset. There are two ways on how we could have done this easier and faster:

1. We could use the colon operator `:`. Similar to last week where we used the colon operator for numerical sequences, we can use it here for selecting a sequence of column names. Here, it reads as "take object `student_HM`, and select columns `year`, and every other column though to `n`".

```{r}
select(Name_Data, year:n)
```

2. We could use "negative selection", i.e. select the variable we wanted to drop by adding a `minus` in front of it.

```{r}
select(Name_Data, -prop)
```

We also have the option of "de-selecting" more than one variable. By including the minus sign before each column we can remove as many as we want.

```{r}
select(Name_Data, -prop, -sex)
```


```{block, type="funfact"}
We can also use `select()` in combination with the `c()` function. Remember, `c()`is "hugging things together". We would put a single `minus` in front of the c rather than each of the column. This will read as exclude every column listed within the brackets.

select(Name_Data, -c(sex, n, prop))
```


Remember, if you don't save this data to an object (e.g. the original dataframe `Name_Data` or under a new name), it won't be saved. We have not saved any of the previous tasks to the `Global Environment`, so there should still be only one babynames related object, e.g. the tibble named `Name_Data`.


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

```{block, type="task"}
**Your turn**

Create a tibble called `Name_Short` that keeps all variables/columns from the data `Name_Data` except from `sex` and `n`. Your new object `Name_Short` should appear in your `Global Environment`.

```


`r hide("Solution")`
```{r, eval = TRUE}
# Jaimie's solution:
Name_Short <- select(Name_Data, -sex, -n)
# OR
Name_Short <- select(Name_Data, -c(sex, n))
# OR
Name_Short <- select(Name_Data, year, name, prop)
```


```{block, type="warning"}
You could also reference the position of column, rather than the actual name.

* select(Name_Data,1,3,5)

While it works code-wise, and seems a much quicker approach, it is a very bad idea in the name of reproducibility. If you send your code to a fellow researcher, they would have no idea what the code does. Moreover, if at some point, you need to add another column to your data, and/or decide to reorder the sequence of your columns, your code would not run anymore the way you expect it to.

```
`r unhide()`


## rename()

`rename()` is a very useful function if we wanted to change column names. All available column are retained, so nothing is lost. If you had 5 variables in a tibble, and wanted to change the name of one of them, your output would be 5 columns in total - one column with a changed name and 4 columns with the previous names. The `rename()` function follows a very simple pattern of

```{r, eval=FALSE}
rename(data, new_column_name = old_column_name)
```

You can rename multiple column headers by including more arguments, separating them with a comma. Let's take a look at a simple example in `table1`.

```{r}
# table1
```

If we wanted to change the column headers of `country` to `Country` and `population` to `Population`, and keep the columns `year` and `cases` as they are, we would code

```{r}
# rename(table1, Country = country,
#        Population = population)
```

If you want to select a few columns and rename them in the process, you could use `select()`. The structure is the same as with `rename()`, the only difference is that the new data only retains the columns mentioned explicitly within `select()`.

```{r, eval=FALSE}
# select(data, new_column_name = old_column_name)
```

Modifying the `rename()` example from above would lead to selecting **only** the columns `country` and `population` from `table1` and renaming them as `Country` and `Population` at the same time.

```{r}
# select(table1, Country = country,
#        Population = population)
```



## arrange()

The `arrange()` function can reorder observations (rows) in ascending (default) or descending order. The first argument to this function is again an object (in this case the tibble `Name_Data`), and the subsequent arguments are the variables (columns) you want to sort by. For example, if you wanted to sort by `n` in **ascending** order (which is the default in `arrange()`) you would type:

```{r}
Name_Arr <- arrange(Name_Data, n)
Name_Arr
```


```{block, type="warning"}
If you were to assign this code to the same object as before (i.e. Name_Data), the previous version of `Name_Data` would be overwritten. 
```


Notice how the `n` column is now organised in alphabetical order i.e. smallest number to largest. Suppose you wanted to reverse this order, displaying largest, you would need to wrap the name of the variable in the `desc()` function (i.e. for **descending**). 

```{r}
Name_Arr2 <- arrange(Name_Data, desc(n))
Name_Arr2
```


You can also sort by more than one column. For example, you could sort by `name` first, and then `n` second: 

```{r}
Name_Arr3 <- arrange(Name_Data, name, n)
Name_Arr3
```

You can also arrange by multiple columns in descending order too, or arrange by one column in ascending order and another in descending order if you wanted.

## filter()

### Single criterion

In order to include or exclude certain observations (rows), use the `filter()` function. The first argument to this function is an object (in this case the tibble `Name_Data`) and the subsequent argument is the criteria you wish to filter on. For example, if you want only those observations from the year of your birth: 

```{r}
Name_MyYear <- filter(Name_Data, year == 1988)
glimpse(Name_MyYear)
```

or keep observations of only popular names:

```{r}
Name_Pop <- filter(Name_Data, prop >= 0.07)
glimpse(Name_Pop)
```


```{block, type="question"}
1. Notice how we saved the new data under a different object name (`Name_MyYear`). When using `filter()`, you should never replace/ overwrite your original data unless you know exactly what you are doing. What could be the consequences?

2. By the way, what do symbols such `==` and `>=` remind you of??? (hint: something we covered last week?)
```

`r hide("Answers")`
```{block, type="solved"}
Consequences: You could potentially lose some data. Nothing is ever completely lost though (unless you are overwriting the original .csv file) but it could result in more work for you to restore everything from the beginning. Especially when your data scripts are very long and analysis is complex (i.e. taking up a lot of computing power), that could easily turn into a nightmare.

Remember the relational operators that returned logical values of either `TRUE` or `FALSE`?
```
`r unhide()`


Relational operators (such as `==`, `!=`, `<`, `<=`, `>`, and `>=`) compare two numerical expressions and return a Boolean variable: a variable whose value is either 0 (`FALSE`) or 1 (`TRUE`). So, essentially, `filter()` includes any observations (rows) for which the expression evaluates to `TRUE`, and excludes any for which it evaluates to `FALSE`. In the previous example, `filter()` sifted through 1924665 observations, keeping rows containing year that was equal to 1998. 


This works as well for columns of the data type `character`. If you want only those observations for a specific name, you could use the equivalence operator `==`. Be aware that a single equals sign (`=`) is used to assign a value to a variable whereas a double equals sign (`==`) is used to check whether two values are equal. 

```{r}
Name_Me <- filter(Name_Data, name == "Jaimie")
glimpse(Name_Me)
```

Here, the `filter()` function compares every single value in the column `name` of the data object `Name_Data` with the character string written on the right-hand side of the equation ("Jaimie").

You can also use `filter()` to keep data from multiple options of the same variable using the `%in%` operator. In this case we want to filter several different names:

```{r}
Name_J <- filter(Name_Data, name %in% c("Jaimie", "Jamie", "Jaime", "James", "Jayme"))
glimpse(Name_J)
```


Because `filter()` evalutes variables against your criteria and keeps observations that are `TRUE`, in essence the function defaults to "filter-in" certain observations. You can however also use it to "filter-out" specific observations, by using the 'not equals' operator `!=`. Here `filter()` keeps every row in which the value DOES NOT read what you have specificed. 

Using `filter()` to exclude certain observations.

```{r}
Name_J_Short <- filter(Name_J, name !="James")
glimpse(Name_J_Short)
```


### Multiple criteria

Often you will come across a situation where you will need to filter based on multiple criteria. For that you have the options of `AND` and `OR`. `AND`is used if you had two criteria and only wanted data returned when **both** criteria are met. `OR`is used if you had two criteria and wanted data returned for **either** criterion.

<center> <img src="images/AND_OR.png" height="150"> </center>

**Simple Example:** Just imagine, you have data of men and women who are either blond or dark-haired.

<center> <img src="images/avatars.png" height="150"> </center>

If you wanted to filter everyone who has *blond* hair **AND** is a *man*, all your data looks like this:

<center> <img src="images/avatars_AND.png" height="150"> </center>

Whereas, if you wanted to filter out everyone who has **either** *dark hair* **OR** is a *woman*, you would get:

<center> <img src="images/avatars_OR.png" height="150"> </center>

<br>

**What does that mean for our babynames data?**

For example, to filter rows containing only your name, of one sex, since your year of birth, you would code:

```{r}
Name_Specific <- filter(Name_Data, name == "Jaimie", year >= 1988, sex == "M")
glimpse(Name_Specific)
```

```{block, type="funfact"}
You could have also used the logical operator `&` (AND) instead of the comma. `filter(Name_Data, name == "Jaimie" & year >= 1988 & sex == "M")` would have given you the same result as above.
```


If we wanted to filter the data `Name_Data` for either names with a very high count **OR** names that account for a very low proportion, we could use the logical operator `|` (OR).

```{r}
Data_Or <- filter(Name_Data, n > 90000 | prop < 2.27e-06)
glimpse(Data_Or)
```

As you will have noticed, `Data_Or` has now observations for names that either have a count over 90,000 in a year, or account for a very small proportion in a year. In this instance these are very distinct groups, and no observation would meet both criteria, check for yourself:


```{r}
Data_Or2 <- filter(Name_Data, n > 90000 & prop < 2.27e-06)
glimpse(Data_Or2)
```

Here we see `Data_Or2`, returns no observations. However sometimes, you might select multiple criteria, where some observations will only meet one, but other observations may meet both criteria (see below). So always keep in mind what exactly you want to find, and choose the best way to filter. 

```{r}
Data_Or3 <- filter(Name_Data, n > 90000 | prop > 0.05)
glimpse(Data_Or3)

Data_Or4 <- filter(Name_Data, n > 90000 & prop > 0.05)
glimpse(Data_Or4)
```

<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

How many rows (or observations) does the object `Data_Or3` contain? `r fitb("172")`<br>
How many different female names are in `Data_Or4`? `r fitb("1")` <br>

<br>


```{block, type="task"}
**Your turn**

Make a tibble called `Name_Beat` that only shows data from `Name_Data` for the `names` John, Paul, George and Ringo, and just for `sex` males.
```

`r hide("Solution")`
```{r}
Name_Beat <- filter(Name_Data, name %in% c("John", "Paul", "George", "Ringo"), sex == "M")

# If you have done this correct you should be able to produce a nice simple plot with the code below, to show change in proportional representation of these names over time (don't worry about what this code means, you'll learn more about plots later in the course)

ggplot(Name_Beat, aes(year, prop, colour=name)) + geom_line()

```
`r unhide()`


## mutate()

The `mutate()` function creates new variables (columns) onto the existing object. The first argument to this function is an object from your `Global Environment` (for example `Name_Data`) and the subsequent argument is the new column name and what you want it to contain. The following image was downloaded from https://www.sharpsightlabs.com/blog/mutate-in-r/

<center> <img src="images/mutate.png" height= "350"> </center>

Let's apply this to this to our `Name_Data` data tibble. Say we wanted to create a new column `Decade` that shows us the relative decade each observation is taken from. Save this as a new object `Name_Ext` to the `Global Environment` rather than overwriting `Name_Data` so that we can compare `Name_Data` with the extended `Name_Ext` later on.

```{r}
Name_Ext <- mutate(Name_Data, Decade = floor(year/10)*10)
glimpse(Name_Ext)
```

As we can see, `Name_Ext` has one column more than `Name_Data`. So `mutate()` took the value in the cells for each row of the variable `year`, devided it by 10, and using the `floor()` function, rounds that value down to the nearest whole number, before finally multiplying the result by 10, and adding it to a new column called `Decade`.

Importantly, new variables will overwrite existing variables if column headings are identical. So if we wanted to halve the values in column `Decade` and store them in a column `Decade`, the original `Decade` would be overwritten. To demonstrate we will try doing this and stroring the output in a new object called `Name_Ext2`and save that to our `Global Environment`.

```{r}
Name_Ext2 <- mutate(Name_Ext, Decade = Decade/2)
glimpse(Name_Ext2)
```

So now, `Name_Ext2` did not gain a column (it still contains 6 variables), and `Decade` now has (unhelpfully) half the numeric value of the decade. (As an aside you could prevent yourself from accidentally doing something like this by converting `Decade` from numeric double type data to character type data, if you had no intention of carrying out any calculations on that variable)


```{block, type="info"}
The main take-away message here is to always check your data after manipulation if the outcome is really what you would expected. If you don't inspect and accidentally overwrite columns, you would not notice any difference.
```


You can also use `mutate()` to drop columns you no longer need, as an alternative to the `select()` function. This would mean that `Name_Ext2` is now identical to `Name_Data`.

```{r}
Name_Ext2 <- mutate(Name_Ext2, Decade = NULL)
glimpse(Name_Ext2)
```


If you want to add more than 2 columns, you can do that in a single `mutate()` statement. You can also add variables that are not numerical values, such as `character` or `logical`. 

Add two columns to `Name_Ext` and call it `Name_Ext3`.

* Column 1 is called `MinName` and is of datatype `logical`. It contains a comparison of the value in `n` with the cut off count of 5 that allows inclusion in the dataset. Values of 5 should read `TRUE`, all other values `FALSE`.
* Column 2 is called `"20thCent"` and is of datatype `logical`. It contains a comparison of the value in `years` ensuring the value is between 1900 and 1999. Values inside this range should read `TRUE`, all other values `FALSE`.

```{r}
Name_Ext3 <- mutate(Name_Ext, MinName = n == 5, "20thCent" = year >= 1900 & year <= 1999)
glimpse(Name_Ext3)
```

```{block, type="solved"}
You may have noticed we needed to put the name of our new column `"20thCent"` inside quotation marks. This is because that name would begin with numeric values which R will interpret as numeric values to be evaluated as code by default, which will then break our code. By placeing the name within quotation marks this tells R to treat this as a standard character string instead. It is always best to avoid creating variables with names that start with a number for this reason, but if it is necessary this is how you can work around it.
```



```{block, type="task"}
**Your turn**

* Add a new column to `Name_Ext3` that is called `Prcnt` that gives the percentage each name accounts for of total names that year. *Hint: `prop` is that same stat represented as a proportion. 

```


`r hide("Solution")`
```{r}
Name_Ext4 <- mutate(Name_Ext3, Prcnt = prop * 100)
glimpse(Name_Ext4)
```
`r unhide()`

### Read in second dataset

At this point we are reaching the end of the usefulness of the Babynames dataset (there is only so much you can do with 5 basic variables), and this is a good time to bring in the second dataset we mentioned.

The second dataset, is a set of career and performance statistics of MMA athletes. You need to read the file `CareerStats.csv` containing your data into your `Global Environment` using the function `read_csv()`. Remember to store your data in an appropriately named object (e.g. `MMA_Data`). 

```{r}
MMA_Data <- read_csv("data/CareerStats.csv")
```

```{block, type="info"}
As you can see this dataset has a lot more variables, which should make for more interesting ways of manipulating the data.
```

## summarise()

In order to compute summary statistics such as mean, median and standard deviation, use the `summarise()` function. This function creates a new tibble of your desired summary statistics. The first argument to this function is the data you are interested in summarising; in this case the object `MMA_Data`, and the subsequent argument is the new column name and what mathematical operation you want it to contain. You can add as many summary statistics in one `summarise()` function as you want; just separate them by a comma. 

```{block, type="info"}
You can use the help function to find out more about the kind of summary stats you can extract.

Some of the most useful however are:
`sum()` - sum total
`n()` - count of observations 
`n_distinct()` - count of distinct (unique) observations
`mean()` - measure of central tendency; mean
`median()` - measure of central tendency; median
`sd()` - standard deviation
`IQR()` - interquartile range
`min()` - the maximum available value in observations
`max()` - the minimum available value in observations

```


Lets start generating some summary stats. For example, say you want to work out the average number of total fights (`T_Fights`) among the athletes and accompanying standard deviation for the entire sample:

```{r}
summarise(MMA_Data, Avg_Mean = mean(T_Fights), SD = sd(T_Fights))
```
 

Therefore, the average number of total fights for all the athletes in our sample is 22.98, with a standard deviation of 9.8.

Let's try another. what is the maximum and minimum hights for the entire sample?
```{r}
summarise(MMA_Data, Minimum = min(Height), Maximum = max(Height))
```

Or maybe we want to know how many different (distinct) weightclasses are there in our dataset?

How would we check that?
```{r}
summarise(MMA_Data, WeightClasses = n_distinct(WeightClass))
```


## Adding group_by()

Now that's all well and good, but in research we are most often interested in drawing comparisons and analysing differences (Between different groups of people, between different treatment types, between different countries etc.).

This is where the `group_by()` function comes in handy. It can organise observations (rows) by variables (columns), thereby spliting the data up into subsets that can be analysed independently. The first argument to this function is the data you wish to organise, in this case `MMA_Data` and the subsequent argument is your chosen grouping variable you want to organise by (e.g. group by). Here we are grouping by weightclass, and saving this as a new object `MMA_G_Weight`; 

```{r}
MMA_G_Weight <- group_by(MMA_Data, WeightClass)
```

If you view the object `MMA_G_Class`, it will not look any different to the original dataset (`MMA_Data`). However, be aware that the underlying structure has changed. In fact, you could use `glimpse()` to double check this. 

```{r}
glimpse(MMA_G_Weight)
```

You can now feed this grouped dataset (`MMA_G_Weight`) into the previous code line to obtain summary statistics by `WeightClass`, the code for finding summary statistics of average number of total fights, has been provided.:

```{r}
Sum_Fights <- summarise(MMA_G_Weight, Avg_Mean = mean(T_Fights), SD = sd(T_Fights))
```


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

Which weightclass has the highest maximum height?  `r fitb("Heavyweight")`


```{block, type="task"}
**Your turn**

* Try to fill out the code for finding summary stats of minimum and maximum height by `WeightClass`:

```


`r hide("Solution")`
```{r}
Sum_Height <- summarise(MMA_G_Weight, Minimum = min(Height), Maximum = max(Height))
```
`r unhide()`


```{block, type="info"}
You can technically group by any variable! For example, there is nothing stopping you from grouping by a continuous variable like age or height. R will allow you to group by a numerical variable that is type double, the code will run. 

However you probably want to be more careful in choosing a categorical variable as grouping criteria. These will usually be character, or interger or even logical data types. However interger data type might also actually represent a continuous variable (but might have only been recorded in whole numbers), and a variable that is character type may not represent a useful category (like idividual ID's for example). 

The point is R does not know what your dataset is actually about, and what your variables are meant to represent... R has no idea if your variable *should* be categorical or not. So it's up to you to know what are sensible variables to use in the `group_by()` function.

```

You might also want to calculate and display the number of individuals from your dataset that are in different groups. This can be achieved by adding the summary function `n()` once you have grouped your data. the function `n()`, simply counts the number of observations and takes no arguments. Here we will group by `Stance` and count the number of athelets in each category:

```{r}
MMA_G_Stance <- group_by(MMA_Data, Stance)

Stance_Ns <- summarise(MMA_G_Stance, N = n())
Stance_Ns
```

<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

How many athletes in the dataset have a Southpaw stance?  `r fitb("45")` <br>
How many athletes in the dataset have an Orthodox stance?  `r fitb("140")`

Finally, it is possible to add multiple grouping variables. For example, the following code groups `MMA_Data` by `ReachClass` and `Stance` and then calculates the mean and standard deviation of average number of strikes landed per minute (`TLpM`) for each group (6 groups). 

```{r}
MMA_G_RS <- group_by(MMA_Data, ReachClass, Stance)
MMA_LpM <- summarise(MMA_G_RS, Mean = mean(TLpM), SD = sd(TLpM))
MMA_LpM
```
 

So far we have not had to calculate any summary statistics with any missing values, denoted by `NA` in R. Missing values are always a bit of a hassle to deal with. Any computation you do that involves `NA` returns an `NA` - which translates as "you will not get a numeric result when your column contains missing values". Missing values can be removed by adding the argument `na.rm = TRUE` to calculation functions like `mean()`, `median()` or `sd()`. For example, lets try to calulate a mean where we have some missing values:

```{r}
Weight_Reach <- summarise(MMA_G_Weight, Avg_Reach = mean(Reach))
Weight_Reach
```
The code runs without error, however you will notice we have a few stats missing (`NA`). Now lets tell R to remove any missing values when making its calculation.

```{r}
Weight_Reach <- summarise(MMA_G_Weight, Avg_Reach = mean(Reach, na.rm = T))
Weight_Reach
```

```{block, type="info"}
Finally...
If you need to return the data to a non-grouped form, use the `ungroup()` function.
```

```{r}
MMA_Data <- group_by(MMA_Data, BMI)
glimpse(MMA_Data)
MMA_Data <- ungroup(MMA_Data)
glimpse(MMA_Data)
```


## The pipe operator (%>%) {#pipes}

As you may have noticed, your environment pane has become increasingly cluttered. Indeed, every time you introduced a new line of code, you created a uniquely-named object (unless your original object is overwritten). This can become confusing and time-consuming. One solution is the pipe operator (`%>%`) which aims to increase efficiency and improve the readability of your code. The pipe operator (`%>%`) read as **"and then"** allows you to chain functions together, eliminating the need to create intermediary objects. This creates a "pipeline", allowing the "flow" of data between lines of code, as the output of one function "flows" into the next function. There is no limit as to how many functions you can chain together in a single pipeline.

For example, in order to `filter()`, `group_by()` and `summarise()` the data, you would have used the following code lines:

```{r}
Example_6a <- filter(MMA_Data, ReachClass == "Above")
Example_6b <- group_by(Example_6a, WeightClass)
Example_6c <- summarise(Example_6b, MeanSub = mean(SubAtt_Avg))
Example_6c
```

However, utilisation of the pipe operator (`%>%`) can simplify this process and create only one object (`Example_7`) as shown:

```{r}
Example_7 <- MMA_Data %>%
  filter(ReachClass == "Above") %>%
  group_by(WeightClass) %>%
  summarise(MeanSub = mean(SubAtt_Avg))
Example_7
```

As you can see, `Example_7` produces the same output as `Example_6c`. So, pipes automatically take the output from one function and feed it directly to the next function. Without pipes, you needed to insert your chosen dataset as the first argument to every function. With pipes, you are only required to specify the original dataset (i.e  `MMA_Data`) once at the beginning of the pipeline, and removes the need to create unnecessary intermediary objects. You now no longer need the first argument of each of the subsequent functions anymore, because the pipe will know to look at the output from the previous step in the pipeline.


```{block, type="task"}
**Your turn**

Amend all of your code from Question8 and turn it into a single pipeline
Save this as an object called `Q9` to your `Global Environment`.
```

`r hide("Solution")`
```{r}
#Jaimie's solution
Q9 <- MMA_Data %>%
  select(ID, WeightClass, Stance, T_Wins, W_by_Decision, "W_by_KO/TKO", W_by_Sub) %>%
  filter(Stance != "Southpaw") %>%
  mutate(Perc_W_by_Dec = (W_by_Decision/T_Wins)*100) %>%
  group_by(WeightClass) %>%
  summarise(AvgPercDec = mean(Perc_W_by_Dec))
Q9
```
`r unhide()`

If done correct `Q9` should look identical to `Q8e`


```{block, type="funfact"}

Note that in the above code chunk, the data object has been on its own line in the code followed immediately by `%>%` before starting with the "functions". 

The other option would have been to put the data object as the first argument within the first function. 

The benefit of having the data on its own is that you can reorder functions easily or squeeze another one in (for example if you summarised something but forgot to group beforehand) without the need to "move" the data object into the new first argument of the pipeline. 

```


## Pipes with the Wickham Six

The next part of this chapter will focus on practicing the Wickham Six functions, but this time we will be implementing piped solutions. 

### select()

First up lets try to narrow down this big data set, by taking `MMA_Data`, and selecting only the variables; `ID`, `Height`, `Weight`, `BMI`, `Reach` and `Stance`. We will store this in `Example_1`.

```{r}
Example_1 <- MMA_Data %>% select(ID, Height, Weight:Reach, Stance)
Example_1
```

```{block, type="info"}
Notice, this could also have been written as follows;
`Example_1 <- MMA_Data %>% select(ID, Height, Weight, BMI, Reach, Stance)`

We can use the `:` operator to sequence together columns that are next to each other in the original dataframe, this can save time but it is not necessary.
```


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

```{block, type="task"}
**Your turn**

Using `select()` keep everything from `Example_1` but except `Reach`, and store this in an object names `Q1`.

```

`r hide("Solution")`
```{r}
# Sean's solutions
Q1 <- Example_1 %>% select(-Reach)
#OR
Q1 <- Example_1 %>% select(ID, Height, Weight, BMI, Stance)
```
`r unhide()`


### arrange()

Lets move on to `arrange()`; lets repeat the steps we did to make `Example_1`, and then arrange it first by `Weight`, then by `BMI`, we'll store this in `Example_2`.

```{r}
Example_2 <- MMA_Data %>% 
  select(ID, Height, Weight:Reach, Stance) %>%
  arrange(Weight, BMI)
Example_2
```

<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

What is the height of the top entry in `Example_2`? `r fitb("69")`

```{block, type="task"}
**Your turn**

In one continuous pipe chain:

Take `MMA_Data` and select only the variables; `ID`, `Height`, `Weight`, `BMI`, `Reach` and `Stance` 
AND THEN
use the arrange() function to sort first by `Reach` in *desceding* order, then by `Height` in *ascending* order. 

Store the result in `Q2`.
```

`r hide("Solution")`
```{r}
# Sean's solution
Q2 <- MMA_Data %>% 
  select(ID, Height, Weight:Reach, Stance) %>% 
  arrange(desc(Reach), Height)
```
`r unhide()`


What is the `BMI` of the top entry in `Q2`? `r fitb("27.042")`


### filter()

Now onto `filter()` which has so many uses! Lets filter out all the athletes who are *over* 31 years of age
```{r}
Example_3 <- MMA_Data %>% filter(Age <=31)
Example_3
```


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

How many athletes (observations) are left in `Example_3`? `r fitb("97")`


```{block, type="task"}
**Your turn**

Using `filter()`, take the original table `MMA_Data` and keep only those athletes in the 'Flyweight' and 'Lightweight' `WeightClasses` Store the result in `Q3`.

```

`r hide("Solution")`
```{r}
# Sean's solution
Q3 <- MMA_Data %>% filter(WeightClass %in% c("Flyweight", "Lightweight"))
```
`r unhide()`

How many athletes (observations) are left in `Q3`? `r fitb("50")`



```{block, type="task"}
**Your turn**

Now try taking the original table `MMA_Data` and keep only those athletes from the "Welterweight" `WeightClass`, who are over 72 inches in `Height`. Store the result in `Q4`.
Hint: remember they will need to match *both* conditions 
```

`r hide("Solution")`
```{r}
# Sean's solution
Q4 <- MMA_Data %>% filter(WeightClass == "Welterweight", Height > 72)
```
`r unhide()`


How many athletes (observations) are left in `Q4`? `r fitb("18")`

```{block, type="task"}
**Your turn**

In one continuous pipe chain:

Take `MMA_Data` and keep only the `Stance`, `T_Fights` and `W_by_Sub` columns
AND THEN
Keep only those athletes who have the "Orthodox" `Stance` *AND* have 27 or more total fights (`T_Fights`) *OR* 15 or more wins by submission (`W_by_Sub`). Store the result in `Q5`.
- Hint - No matter what they need to have the `Orthodox` stance, regardless of the other conditions 
```

`r hide("Solution")`
```{r}
# Sean's solution
Q5 <- MMA_Data %>%
  select(Stance, T_Fights, W_by_Sub) %>%
  filter(Stance == "Orthodox" & (T_Fights >= 27 | W_by_Sub >= 15))
#OR
Q5 <- MMA_Data %>%
  select(Stance, T_Fights, W_by_Sub) %>%
  filter(Stance == "Orthodox", (T_Fights >= 27 | W_by_Sub >= 15))
```
`r unhide()`

`r hide("Explain This Answer")`
```{block, type="solved"}
There is essentially 2 parts to this question; the first criteria is to find athletes who have the "orthodox" stance... that's the first requirement... then *if* they matched that criteria, we want to check, if they have *EITHER* 27 or more total fights *OR* 15 or more wins by submission, which is why we need to put the second "either/or" criteria in brackets, so R knows to treat them together.

If you take the brackets out, it will treat the first two criteria as a joint criteria and the `|` "Or" operator creates the break. Meaning R thinks you are asking for; Athletes with the orthodox stance and 27 or more total fights... *OR* athletes with 15 or more wins by submission. Try running the code without the brackets and seeing what happens

`Q5Alt <- MMA_Data %>% select(Stance, T_Fights, W_by_Sub) %>% filter(Stance == "Orthodox" & T_Fights >= 27 | W_by_Sub >= 15)`

Hopefully now you can understand the difference.

```
`r unhide()`

How many athletes (observations) are left in `Q5`? `r fitb("44")`


### mutate()

Moving on to mutate() now.

Lets add a new column onto the table `Example_1`, that shows `Reach` but in meters rather than inches, and we'll call it `ReachM`. We can make this column with `mutate()` by converting the inches value in the original `Reach` column into centimeters, by multiplying (`*`) the value by `2.54` and then dividing (`/`) the result by `100`.

```{r}
Example_4 <- Example_1 %>% mutate(ReachM = (Reach*2.54)/100)
Example_4
```


<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

```{block, type="task"}
**Your turn**

Take the table `Example_1` and mutate a new column onto it called `BMI_Alt`, this time attempting to recalculate BMI using the Weight and Height variables. The calculation for BMI is; weight in kilograms devided by height in meters squared. Lets break down the steps, you will need to;
- multiply `Weight` by 0.453 (to convert lbs to kgs)
- divide that by...
- `Height` multiplied 2.54 (to convert inches to cm), which you divide by 100 (to convert to m), which you then square
Store the result in `Q5`.

- Hint - the `^` symbol is for calculating "to the power of"
```

`r hide("Solution")`
```{r}
# Sean's solution
Q6 <- Example_1 %>% mutate(BMI_Alt = (Weight*0.453)/(((Height*2.54)/100)^2))
```
`r unhide()`

```{block, type="info"}
Don't be worried if your new column is different by a few decimals (the original BMI was created with a slightly different calculation with different rounding). If they look approximately similar you have done it correctly.
```



### group_by() and summarise()

Now let's brush up on group_by and summarise().

Here we will take the original table `MMA_Data` and group that data by `WeightClass`.
Then we will create `mean()` summary stats for: 
Number of hits landed per minute (`TLpM`) and we'll call that column `MeanHit`, 
Number of hits absorbed per minute (`AbpM`) and we'll call that column `MeanAbsorb`, 
And average fight length (`Time_Avg`) and we'll call that column `MeanTime`.
```{r}
Example_5 <- MMA_Data %>% 
  group_by(WeightClass) %>%
  summarise(MeanHit = mean(TLpM), MeanAbsorb = mean(AbpM), MeanTime = mean(Time_Avg))

# OR

Example_5 <- group_by(MMA_Data, WeightClass) %>% # we could skip the first pipe if we wanted
  summarise(MeanHit = mean(TLpM), MeanAbsorb = mean(AbpM), MeanTime = mean(Time_Avg))
```

<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

Which weightclass has the highest Hit average? `r fitb("LightHeavyweight")` <br>
Which weightclass has the lowest Absorbtion average? `r fitb("Flyweight")` <br>
Which weightclass has the highest average time? `r fitb("Flyweight")` <br>


```{block, type="task"}
**Your turn**

In one continuous pipe chain:

Take the original table `MMA_Data` and group that data by `Stance` and `HeightClass`
AND THEN
Create summary stats for success rate (`Success`), you should have columns called;
`MedSuccess` that shows the median success rate
`MaxSuccess` that shows the maximum success rate
`MinSuccess` that shows the minimum success rate
`SDSuccess` that shows the standard deviation of success rate
The resulting table should be stored in `Q7`.
```

`r hide("Solution")`
```{r}
# Sean's solution
Q7 <- MMA_Data %>%
  group_by(Stance, HeightClass) %>%
  summarise(MedSuccess = median(Success), 
            MaxSuccess = max(Success), 
            MinSuccess = min(Success), 
            SDSuccess = sd(Success))
```
`r unhide()`


Which Stance/HeightClass combo has the highest median success rate? (enter your answers in the format Stance/HeightClass) `r fitb("Swithc/Tall")` <br>
What is the minimum success rate of tall athletes with an orthodox stance? `r fitb("0.415")` <br>
What is the standard deviation in success rate for short athletes with a southpaw stance? (write your answer to 3 decimal places) `r fitb("0.062")` <br>


### Bringing it all together 

<span style="font-size: 22px; font-weight: bold; color: hsl(24, 100%, 50%);">Question Time</span>

```{block, type="task"}
**Your turn**

In one continuous pipe chain:

* Take the original table `MMA_Data`, and select only `ID`, `WeightClass`, `Stance`, `T_Wins`, `W_by_Decision`, `W_by_KO/TKO` and `W_by_Sub`
* Filter out all the athletes with the "Southpaw" `Stance`
* Add on a new column called `Perc_W_by_Dec` that shows the percentage of total wins (`T_Wins`) that are accounted for by decisions (`W_by_Decision`)
* Group the data by `WeightClass`
* Create summary stats that show the mean of `Perc_W_by_Dec`

Store the result in a variable called `Q8`.
```

`r hide("Solution")`
```{r}
# Sean's solution
Q8 <- MMA_Data %>% 
  select(ID, WeightClass, Stance, T_Wins, W_by_Decision:W_by_Sub) %>%
  filter(Stance != "Southpaw") %>%
  mutate(Perc_W_by_Dec = (W_by_Decision/T_Wins)*100) %>%
  group_by(WeightClass) %>%
  summarise(AvgPercDec = mean(Perc_W_by_Dec))
```
`r unhide()`

Which weightclass has the lowest average percentage of wins by decision? `r fitb("Heavyweight")`



